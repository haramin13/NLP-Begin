import regex as re
import normalized as norm
import preprocessing as pre
import sys
# from underthesea import word_tokenize

# txt = "ğŸ‘‰ App Store: https://bom.to/5g0S0U ğŸ‘‰ Google Play: https://bom.to/kij1st #CircleKVietnam #Verytiá»‡nVerylá»£i #AppthÃ nhviÃªnCKClub #CKClub"
# txt = norm.convert_unicode(txt)
# txt = norm.chuan_hoa_dau_cau_tieng_viet(txt)
# txt = re.sub("#[A-Za-z0-9_]+","", txt)
# print(txt)

# txt = "Há»i gÃ¬ Ä‘Ã¡p náº¥y 0 2 1"
# # (?i) lÃ  flag ignore case (khÃ´ng phÃ¢n biá»‡t kÃ½ tá»± thÆ°á»ng vÃ  hoa)
# arr = regex.findall(r'(?i)\b\p{L}+\b', txt)
# print(arr)

# txt = "Moot ngaá»³ Ä‘áº¹p trÆ¡Ã¬"
# txt = norm.convert_unicode(txt)
# print(txt)
# txt = norm.chuan_hoa_dau_cau_tieng_viet(txt)
# txt = pre.remove_emoji(txt)
# print(txt)

txt = "ğŸ‘‰ App Store: https://bom.to/5g0S0U ğŸ‘‰ Google Play: https://bom.to/kij1st #CircleKVietnam #Verytiá»‡nVerylá»£i #AppthÃ nhviÃªnCKClub #CKClub"
txt = norm.convert_unicode(txt)
print(txt)
txt = pre.remove_url(txt)
txt = pre.remove_emoji(txt)
txt = pre.remove_hashtag(txt)
txt = pre.remove_space(txt)
print(txt)
print(len(txt))